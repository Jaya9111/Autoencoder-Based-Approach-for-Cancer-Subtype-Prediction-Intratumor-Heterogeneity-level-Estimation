# -*- coding: utf-8 -*-
"""Autoencoder_Boruta.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ue8AJP1LBYIWEE6qDoO9KmZc0NffCfCA

## Import the libraries
"""

import pandas as pd
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import warnings
import collections
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

"""## Load the Datasets and show the top most data"""

# Load RNA-Seq dataset
rna_df = pd.read_csv("/content/drive/MyDrive/Jaya New Files/RNA seq_3582_reduced_features.csv",index_col=0)
# Load mutation dataset
mutation_df = pd.read_csv("/content/drive/MyDrive/Jaya New Files/Mutation_1197_kreduced_features.csv",index_col=0)
# Load methylation dataset
methylation_df = pd.read_csv("/content/drive/MyDrive/Jaya New Files/HumanMethylation_1098_reduced_features.csv",index_col=0)
#load clinical datset
clinical_df = pd.read_csv("/content/drive/MyDrive/Jaya New Files/BRCA-subtypes-combined-tumor-samples-only-gdc-tcga-refined.csv",index_col=0)

#rna_df = rna_df.set_index('sample')
#methylation_df = methylation_df.set_index('sample')
#mutation_df = mutation_df.set_index('sample')

import pandas as pd

# Calculate the mean and standard deviation for each column
mean_values = rna_df.mean()
std_values = rna_df.std()

# Apply zero score normalization to each column
normalized_rna_df = (rna_df - mean_values) / std_values

# The 'normalized_rna_df' DataFrame now contains the normalized data.

normalized_rna_df = normalized_rna_df.fillna(0)
normalized_rna_df

mutation_df = mutation_df.fillna(0)
mutation_df

import pandas as pd

# Calculate the mean and standard deviation for each column
mean_values = methylation_df.mean()
std_values = methylation_df.std()

# Apply zero score normalization to each column
normalized_methylation_df = (methylation_df - mean_values) / std_values

# The 'normalized_rna_df' DataFrame now contains the normalized data.

normalized_methylation_df = normalized_methylation_df.fillna(0)
normalized_methylation_df

clinical_df

# Remove the "-01" suffix from the sample names
clinical_df.index = clinical_df.index.str.replace(r'-01$', '', regex=True)

clinical_df

#from sklearn import preprocessing
#le = preprocessing.LabelEncoder()
#new_label= le.fit_transform(clinical_df["Subtype_mRNA_PANCAN"])
#clinical_df["Subtype_mRNA_PANCAN"] = new_label
#clinical_df

"""## Merge the Datasets"""

print(normalized_methylation_df.columns)
print(normalized_rna_df.columns)
print(mutation_df.columns)
print(clinical_df.columns)

cols = mutation_df.columns.values
cols
mutation_df2 = mutation_df.copy()
mutation_df2.columns = [str(i)+"_mut" for i in cols]
mutation_df2 =mutation_df2.fillna(0)
mutation_df2

merged_df = normalized_methylation_df.join(mutation_df2, how = 'inner')
merged_df =merged_df.fillna(0)
merged_df

merged_df = merged_df.join(normalized_rna_df, how = 'inner')
merged_df =merged_df.fillna(0)
merged_df

merged_df = merged_df.join(clinical_df, how = 'inner')
merged_df =merged_df.fillna(0)
merged_df

collections.Counter(merged_df["Subtype_mRNA_PANCAN"].values)

"""## Calculate the pca of the merged dataset

---


"""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import matplotlib.colors
from sklearn.cluster import KMeans
# Create PCA object with desired number of components
pca = PCA(n_components=2)

# Fit PCA on merged dataset
merged_df2 = merged_df.select_dtypes(include=np.number)
pca.fit(merged_df2)

# Transform the merged dataset using the fitted PCA
pca_df = pd.DataFrame(pca.transform(merged_df2), columns=['PC1', 'PC2'])
pca_df

# Define the colors for the different clusters
colors = ['red', 'green', 'blue', 'yellow', 'black']
c_values = merged_df["Subtype_mRNA_PANCAN"].values.tolist()

# Convert categorical values to numerical labels
label_encoder = LabelEncoder()
c_labels = label_encoder.fit_transform(c_values)

# Create a scatter plot of the PCA-transformed data, with each point colored according to its predicted cluster label
plt.scatter(pca_df['PC1'], pca_df['PC2'], c=c_labels, cmap=matplotlib.colors.ListedColormap(colors))

# Add a colorbar to the plot
cb = plt.colorbar()
cb.set_ticks(np.unique(c_labels))
cb.set_ticklabels(label_encoder.classes_)

# Add axis labels and a title to the plot
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Analysis of cancer subtypes on merged Data')

# Show the plot
plt.show()

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(merged_df2)
y_predmerge = kmeans.predict(merged_df2)
y_predmerge

import matplotlib.pyplot as plt
import matplotlib.colors
from sklearn.decomposition import PCA

# Perform PCA on the encoded data
pca = PCA(n_components=2)
X_pca = pca.fit_transform(merged_df2)

# Define the colors for the different clusters
colors = ['red', 'green', 'blue', 'yellow', 'black']

# Create a scatter plot of the PCA-transformed data, with each point colored according to its predicted cluster label
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_predmerge, cmap=matplotlib.colors.ListedColormap(colors))

# Add a colorbar to the plot
cb = plt.colorbar()
cb.set_ticks([0, 1, 2, 3, 4])
cb.set_ticklabels(['Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4'])

# Add axis labels and a title to the plot
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Analysis of K-mean Cancer subtype on Merged data)')

# Show the plot
plt.show()

merged_df2.columns

from sklearn.model_selection import train_test_split

# Split the dataset into train and test sets
X_train, X_test = train_test_split(merged_df2, test_size=0.2, random_state=42)

X_train

X_train.columns

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')

from keras.layers import Input, Dense, BatchNormalization, Dropout
from keras.models import Model
from keras.callbacks import History, EarlyStopping
from keras.regularizers import l1_l2

# Define a History object to store the loss values during training
history = History()

# Define early stopping criteria
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Define the number of input features
input_dim = X_train.shape[1]

# Define the input layer
input_layer = Input(shape=(input_dim,))

# Define the first hidden layer with higher dimension than input layer
hidden_layer_1 = Dense(128, activation='relu')(input_layer)
#hidden_layer_1 = BatchNormalization()(hidden_layer_1)
hidden_layer_1 = Dropout(0.5)(hidden_layer_1)

# Define the encoding layer
encoded_layer = Dense(64, activation='relu')(hidden_layer_1)

# Define the second hidden layer with higher dimension than input layer
hidden_layer_2 = Dense(128, activation='relu')(encoded_layer)
#hidden_layer_2 = BatchNormalization()(hidden_layer_2)
hidden_layer_2 = Dropout(0.5)(hidden_layer_2)

# Define the decoding layer
decoded_layer = Dense(input_dim, activation='sigmoid')(hidden_layer_2)

# Define the autoencoder model
autoencoder = Model(input_layer, decoded_layer)

# Compile the autoencoder model
autoencoder.compile(optimizer='adam', loss='mean_squared_error')

# Fit the autoencoder model to the training data, while passing the History and EarlyStopping objects as callbacks
autoencoder.fit(X_train, X_train,
                epochs=50,
                batch_size=32,
                shuffle=True,
                validation_data=(X_test, X_test),
                callbacks=[history, early_stopping])

# Retrieve the loss values from the History object
train_loss = history.history['loss']
val_loss = history.history['val_loss']

# Plot the loss values using matplotlib
import matplotlib.pyplot as plt

epochs = range(1, len(train_loss) + 1)

plt.plot(epochs, train_loss, 'g', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

autoencoder.summary()

"""## Extract the encoder model"""

encoder = Model(input_layer, encoded_layer)

"""## Use the encoder model to encode the train and test sets"""

X_train_encoded = encoder.predict(X_train)
X_test_encoded = encoder.predict(X_test)

"""##Use the encoder model to encode the merged data set"""

X_encoded = encoder.predict(merged_df2)

"""##AUTOENCODER OUTPUT DF"""

encodedoutput_df = pd.DataFrame(X_encoded)
encodedoutput_df

encodedoutput_df.index = merged_df2.index
encodedoutput_df

def depth2(data):
    #input is a pandas data frame with gene expression values
    dt = data.T
    result = dt.apply(lambda col: (col-col.mean())/col.std())
    result = result.replace(np.nan,0)
    result = result.apply(lambda col: abs(col)).T
    return result.std()

df = pd.read_csv("/content/drive/MyDrive/Jaya New Files/Encodedoutput_features.csv", index_col=0)
df

df2 = pd.DataFrame(depth2(df.T), columns=['Heterogeneity_Score'])
df2.index.name='sampleID'
df2

#encodedoutput_df.to_csv("Encodedoutput_features.csv")

"""## Perform k-means clustering on the encoded data"""

#from sklearn.cluster import KMeans

#kmeans = KMeans(n_clusters=5, random_state=42)
#kmeans.fit(X_train_encoded)

from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(encodedoutput_df)

"""

## Use the trained k-means model to predict the clusters on the test set"""

y_pred = kmeans.predict(encodedoutput_df)

"""## Print the predicted cluster labels


"""

y_pred

# Create a bar plot of the number of samples in each cluster
import seaborn as sns
ax = sns.countplot(x=kmeans.labels_, palette='Set2')
# Calculate the number of samples in each cluster
cluster_counts = [sum(kmeans.labels_ == i) for i in range(len(set(kmeans.labels_)))]

# Add annotations to the bars
for index, count in enumerate(cluster_counts):
    ax.text(index, count + 0.5, str(count), ha='center', va='bottom')

plt.title('Number of samples in each cluster')
plt.xlabel('Cluster')
plt.ylabel('Count')
plt.show()
# This will create a scatter plot of the first two principal components colored by cluster labels and a bar plot of the number of samples in each cluster. You can modify the plots as per your requirements.

from sklearn.metrics import pairwise_distances
from scipy.cluster.hierarchy import linkage, dendrogram, set_link_color_palette
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering

# Reshape y_pred to a 2D array with a single column
y_pred = y_pred.reshape(-1, 1)

# Compute pairwise distances between samples using Euclidean distance
dist_matrix = pairwise_distances(y_pred, metric='euclidean')

# Compute hierarchical clustering
hc = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')
y_hc = hc.fit_predict(dist_matrix)

# Define colors for the dendrogram
color_palette = ['#1f77b4', '#ff7f0e', '#2ca02c']

# Set the color palette for the dendrogram
set_link_color_palette(color_palette)

# Plot the dendrogram
plt.figure(figsize=(10, 5))
dendrogram(linkage(dist_matrix, method='ward'), color_threshold=0, above_threshold_color='blue', orientation='top')
plt.title('Dendrogram')
plt.xlabel('Samples')
plt.ylabel('Distance')
plt.show()

import matplotlib.pyplot as plt

# Generate histogram
plt.hist(y_pred, bins=9)

# Add labels and title
plt.xlabel('Predicted Values')
plt.ylabel('Frequency')
plt.title('Histogram of Predicted Values')

# Show plot
plt.show()

new_df = merged_df[["Subtype_mRNA_PANCAN"]]
y = LabelEncoder().fit_transform(merged_df['Subtype_mRNA_PANCAN'])
new_df["Subtype_mRNA_PANCAN"] = y
new_df

pred_df = pd.DataFrame(y_pred, index=new_df.index, columns=['y_pred'])
pred_df

for true_label in [0,1,2,3,4]:
  for pred_label in [0,1,2,3,4]:
    sample_set1 = set(new_df[new_df["Subtype_mRNA_PANCAN"]==true_label].index.values)
    sample_set2 = set(pred_df[pred_df["y_pred"]==pred_label].index.values)

    jaccard_similarity = len(sample_set1.intersection(sample_set2)) / len(sample_set1.union(sample_set2))
    print("true label",true_label, "predicted label",pred_label,"jaccard similarity", jaccard_similarity)
  print()

# true 0 pred 1 - 0.89
# true 1 pred 2 - 0.36
# true 2 pred 4 - 0.42
# true 3 pred 0 - 0.35
# true 4 pred 3 - 0.15

"""##K-Means clustering on True Labels"""

import matplotlib.pyplot as plt
import matplotlib.colors
from sklearn.decomposition import PCA

# Perform PCA on the encoded data
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_encoded)

# Define the colors for the different clusters
colors = ['red', 'green', 'blue', 'yellow', 'black']
c_values = new_df["Subtype_mRNA_PANCAN"].values.tolist()
categorical_labels = label_encoder.inverse_transform(c_labels)

# Create a scatter plot of the PCA-transformed data, with each point colored according to its predicted cluster label
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=c_values, cmap=matplotlib.colors.ListedColormap(colors))

# Add a colorbar to the plot
cb = plt.colorbar()
cb.set_ticks(np.unique(c_labels))
cb.set_ticklabels(label_encoder.classes_)

# Add axis labels and a title to the plot
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Analysis of cancer subtypes on Extracted Features')

# Show the plot
plt.show()

collections.Counter(new_df["Subtype_mRNA_PANCAN"].values)

"""##K-Means clustering on Predicted Labels"""

import matplotlib.pyplot as plt
import matplotlib.colors
from sklearn.decomposition import PCA

# Perform PCA on the encoded data
pca = PCA(n_components=2)
X_pca = pca.fit_transform(encodedoutput_df)

# Define the colors for the different clusters
colors = ['red', 'green', 'blue', 'yellow', 'black']

# Create a scatter plot of the PCA-transformed data, with each point colored according to its predicted cluster label
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap=matplotlib.colors.ListedColormap(colors))

# Add a colorbar to the plot
cb = plt.colorbar()
cb.set_ticks([0, 1, 2, 3, 4])
cb.set_ticklabels(['Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4'])

# Add axis labels and a title to the plot
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Analysis of K-Mean cancer subtype on Output Features')

# Show the plot
plt.show()

"""## Evaluate the performance of the clustering algorithm"""

from sklearn.metrics import silhouette_score

# Apply PCA to the scaled data
pca = PCA(n_components=2)
X_encoded_pca = pca.fit_transform(encodedoutput_df)

# Apply KMeans clustering to the PCA-compressed representation to detect cancer subtypes
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_encoded_pca)

# Get the cluster assignments
cluster_labels = kmeans.labels_

# Calculate the silhouette score
silhouette_score = silhouette_score(X_encoded_pca, cluster_labels)

print("Silhouette Score:", silhouette_score)

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

# Apply PCA to the scaled data
pca = PCA(n_components=2)
X_encoded_pca = pca.fit_transform(encodedoutput_df)
X_encoded_pca

print(kmeans.labels_.shape)

print(X_encoded.shape)

from sklearn.preprocessing import StandardScaler
# Split the data into train and test sets
X_encoded, X_test = train_test_split(encodedoutput_df, test_size=0.2, random_state=42)

# Scale the data to have zero mean and unit variance
scaler = StandardScaler()
X_encoded_scaled = scaler.fit_transform(X_encoded)
X_test_scaled = scaler.transform(X_test)

# Apply PCA to the data
pca = PCA(n_components=10)
X_encoded_pca = pca.fit_transform(X_encoded_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Apply KMeans clustering to the compressed representation to detect cancer subtypes
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_encoded_pca)
train_labels = kmeans.predict(X_encoded_pca)
test_labels = kmeans.predict(X_test_pca)

# Print the cluster assignments for the first 10 samples in the training and test sets
print("Training set cluster assignments:")
print(train_labels[:10])
print("Test set cluster assignments:")
print(test_labels[:10])

"""##Evaluate the performance of the clustering algorithm **"""

from sklearn.metrics import silhouette_score

# Apply PCA to the scaled data
pca = PCA(n_components=2)
X_encoded_pca = pca.fit_transform(encodedoutput_df)

# Apply KMeans clustering to the PCA-compressed representation to detect cancer subtypes
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_encoded_pca)

# Get the cluster assignments
cluster_labels = kmeans.labels_

# Calculate the silhouette score
silhouette_score = silhouette_score(X_encoded_pca, cluster_labels)

print("Silhouette Score:", silhouette_score)

from sklearn.metrics import calinski_harabasz_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Split the data into train and test sets
X_encoded, X_test = train_test_split(encodedoutput_df, test_size=0.2, random_state=42)

# Scale the data to have zero mean and unit variance
scaler = StandardScaler()
X_encoded_scaled = scaler.fit_transform(X_encoded)
X_test_scaled = scaler.transform(X_test)

# Apply PCA to the data
pca = PCA(n_components=10)
X_encoded_pca = pca.fit_transform(X_encoded_scaled)
X_test_pca = pca.transform(X_test_scaled)

# Apply KMeans clustering to the compressed representation to detect cancer subtypes
kmeans = KMeans(n_clusters=5, random_state=42)
kmeans.fit(X_encoded_pca)

# Get the cluster assignments
cluster_labels = kmeans.labels_

# Calculate the Calinski-Harabasz Index for the clustering
calinski_score = calinski_harabasz_score(X_encoded_pca, cluster_labels)

print("Calinski-Harabasz Index Score:", calinski_score)

"""##load new clinical datset contains intratumor stages & sampleID's"""

import pandas as pd

clinicals_df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/TCGA.BRCA.sampleMap_BRCA_clinicalMatrix",index_col=0,sep="\t")
#for i in clinicals_df.columns:  print(i) ## used to find out the columns of intrarumor pathetic stage
clinicals_df

"""##To see the pathalogic stages of each sample in the df


"""

#for i in clinicals_df[['_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene','pathologic_stage']].values:print(i)

# Define the columns to keep ('miRNA' and 'pathologic_stage')
columns_to_keep = ['_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene','pathologic_stage']

# Keep only the desired columns in the DataFrame
clinicals_df = clinicals_df.loc[:, columns_to_keep]

# Remove the "-01" suffix from the sample names
clinicals_df.index = clinicals_df.index.str.replace(r'-01$', '', regex=True)

#clinicals_df_filtered._GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gen = clinicals_df_filtered._GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gen.str.replace(r'-01$', '', regex=True)
clinicals_df = clinicals_df.fillna(0)

# Print the filtered DataFrame
clinicals_df

"""## Drop _GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene"""

# Drop the '_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene' column
clinicals_df = clinicals_df.drop('_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene', axis=1)

# Display the resulting DataFrame
clinicals_df

"""## Merge the Valid stages"""

import pandas as pd

# Create the mapping to merge the stages
stage_mapping = {
    'Stage IA': 'Stage I',
    'Stage IB': 'Stage I',
    'Stage IIA': 'Stage II',
    'Stage IIB': 'Stage II',
    'Stage IIIA': 'Stage III',
    'Stage IIIB': 'Stage III',
    'Stage IIIC': 'Stage III',
    'Stage IVA': 'Stage IV',
    'Stage IVB': 'Stage IV'
}

# Replace the stages according to the mapping
clinicals_df['pathologic_stage'] = clinicals_df['pathologic_stage'].replace(stage_mapping)

# Define a list of stages to keep
valid_stages = ["Stage I", "Stage II", "Stage III", "Stage IV"]

# Filter the DataFrame to keep only the rows with valid stages
clinicals_df_filtered = clinicals_df[clinicals_df['pathologic_stage'].isin(valid_stages)]

# Display the resulting DataFrame
clinicals_df_filtered

"""## merge the clinical with output of autoencoder"""

# Heterogeneity score
import pandas as pd

common_sample_ids_df = clinicals_df_filtered.join(df2, how='inner')
common_sample_ids_df

# heterogeneity score for shannon entropy
import pandas as pd

common_sample_ids_df3 = clinicals_df_filtered.join(encodedoutput_df, how='inner')
common_sample_ids_df3

len(set([i[:12] for i in common_sample_ids_df.index]))
print()
len(set([i[:12] for i in common_sample_ids_df3.index]))

# Create a new DataFrame with unique SampleID values without considering duplicates
#unique_sample_ids_df = pd.DataFrame({'sampleID': clinicals_df_filtered['_GENOMIC_ID_data/public/TCGA/BRCA/miRNA_HiSeq_gene'].unique()})

# Print the new DataFrame with unique SampleID values
#print(unique_sample_ids_df)

"""## Calculate the Intratumor Shannon entropy"""

from pandas.core.sorting import Level
import pandas as pd
import numpy as np
from scipy.stats import entropy

# Select only the numerical columns for calculating Shannon entropy
numerical_columns = common_sample_ids_df3.select_dtypes(include=[np.number])

# Calculate Shannon entropy for each sample (row) in the DataFrame
def calculate_shannon_entropy(row):
    return entropy(row, base=2)

# Apply the function to calculate Shannon entropy along each row (axis=1)
intratumor_heterogeneity = numerical_columns.apply(calculate_shannon_entropy, axis=1)

# Add the intratumor heterogeneity levels to the merged DataFrame
common_sample_ids_df3['Intratumor_Heterogeneity_Shannon_entropy'] = intratumor_heterogeneity

# Resulting DataFrame with 'Pathologic_Stage' and 'Intratumor_Heterogeneity' columns
common_sample_ids_df3 = common_sample_ids_df3[['pathologic_stage', 'Intratumor_Heterogeneity_Shannon_entropy']]
common_sample_ids_df3

pip install matplotlib seaborn

import matplotlib.pyplot as plt
import seaborn as sns

# Set the style for the plot (optional but makes the plot look nicer)
sns.set(style="whitegrid")

# Define the desired order of pathologic stages
desired_order = ["Stage I", "Stage II", "Stage III", "Stage IV"]

# Set 'pathologic_stage' as an ordered categorical variable
common_sample_ids_df['pathologic_stage'] = pd.Categorical(common_sample_ids_df['pathologic_stage'], categories=desired_order, ordered=True)

# Define the colors for the box plot
colors = ['yellow', 'green', 'blue', 'red']

# Create the box plot
plt.figure(figsize=(10, 6))  # Set the figure size (width, height)
sns.boxplot(x="pathologic_stage", y="Heterogeneity_Score", data=common_sample_ids_df, palette=colors)

# Set labels and title
plt.xlabel("Pathologic Stage")
plt.ylabel("Intratumor Heterogeneity")
plt.title("Box Plot of Intratumor Heterogeneity by Pathologic Stage")

# Show the plot
plt.show()

# Calculate the mean for each 'pathologic_stage'
mean_values = common_sample_ids_df.groupby('pathologic_stage')['Heterogeneity_Score'].mean()

# Calculate the number of samples for each 'pathologic_stage'
sample_counts = common_sample_ids_df3['pathologic_stage'].value_counts()
print(sample_counts)

# Display the mean values
print(mean_values)

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Set the style for the plot (optional but makes the plot look nicer)
sns.set(style="whitegrid")

# Define the desired order of pathologic stages
desired_order = ["Stage I", "Stage II", "Stage III", "Stage IV"]

# Set 'pathologic_stage' as an ordered categorical variable
common_sample_ids_df3['pathologic_stage'] = pd.Categorical(common_sample_ids_df3['pathologic_stage'], categories=desired_order, ordered=True)

# Define the colors for the box plot
colors = ['yellow', 'green', 'blue', 'red']

# Create the box plot
plt.figure(figsize=(10, 6))  # Set the figure size (width, height)
sns.boxplot(x="pathologic_stage", y="Intratumor_Heterogeneity_Shannon_entropy", data=common_sample_ids_df3, palette=colors)

# Set labels and title
plt.xlabel("Pathologic Stage")
plt.ylabel("Intratumor Heterogeneity")
plt.title("Box Plot of Intratumor Heterogeneity_shannon_entropy by Pathologic Stage")

# Show the plot
plt.show()

# Calculate the mean for each 'pathologic_stage'
mean_values = common_sample_ids_df3.groupby('pathologic_stage')['Intratumor_Heterogeneity_Shannon_entropy'].mean()

# Calculate the number of samples for each 'pathologic_stage'
sample_counts = common_sample_ids_df3['pathologic_stage'].value_counts()
print(sample_counts)

# Display the mean values
print(mean_values)

# Calculate the number of samples for each 'pathologic_stage'
sample_counts = common_sample_ids_df3['pathologic_stage'].value_counts()
print(sample_counts)